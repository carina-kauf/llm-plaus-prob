{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71cd4dd-aa42-4a76-ac2c-248d723f1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.container import BarContainer\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from os import listdir\n",
    "import os\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6b2eb5-b8a2-4678-9106-bc4fcd85d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"DTFit\"\n",
    "TASKSET = \"MAIN\" # \"MAIN\" \"GENERATION\" \"QUERY_COMPARISON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb7dfff-0dbf-4e59-b3a0-27914780b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASKSET == \"MAIN\":\n",
    "    task_order = ['logprobs',\n",
    "                  'sentence_comparison',\n",
    "                  'sentence_comparison_metaInstruct',\n",
    "                  # 'word_comparison',\n",
    "                  'sentence_judge_generation_likert',\n",
    "                  'sentence_judge']\n",
    "    FREE_CONSTRAINED_SEPARATED = False\n",
    "elif TASKSET == \"GENERATION\":\n",
    "    task_order = ['logprobs',\n",
    "                   'sentence_comparison_generation_1vs2',\n",
    "                   'sentence_judge_generation_likert']\n",
    "    FREE_CONSTRAINED_SEPARATED = True\n",
    "elif TASKSET == \"QUERY_COMPARISON\":\n",
    "    task_order = ['sentence_comparison']\n",
    "\n",
    "BETTER_TASK_NAMES = {\n",
    "    'logprobs' : \"Log Likelihood\",\n",
    "    'sentence_comparison' : 'Sentence Choice I',\n",
    "    'sentence_comparison_metaInstruct' : 'Sentence Choice II',\n",
    "    'word_comparison' : 'Word Comparison',\n",
    "    'sentence_judge_generation_likert' : 'Likert Scoring\\nGeneration',\n",
    "    'sentence_judge' : 'Sentence Judgment'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf70bb5d-48ad-46f7-8ad2-682f3d594eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [elm for elm in PRETTYNAMES.keys() if elm != \"human\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae52859-9045-424e-8181-6f5d03e4b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "custom_params = {\"axes.spines.right\": False,\n",
    "                 \"axes.spines.top\": False,\n",
    "                 'ytick.left': True,\n",
    "                 'xtick.bottom': True,\n",
    "                'grid.linestyle': \"\" #gets rid of horizontal lines\n",
    "                }\n",
    "sns.set_theme(font_scale=1.4, style=\"white\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbc97dc-933c-4e63-981b-bc982cac75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder):\n",
    "    # Initialize list of dataframes that we will concatenate.]\n",
    "    task = folder.split(\"/\")[-1]\n",
    "    all_data = []\n",
    "    \n",
    "    # Get list of all JSON results files in the folder.\n",
    "    files_to_read = [f for f in listdir(folder) if f.endswith(\".json\")]\n",
    "\n",
    "    # Read each file into a single dataframe.\n",
    "    for f in files_to_read:\n",
    "        # Subset for current dataset!\n",
    "        if not DATASET in f:\n",
    "            continue\n",
    "        with open(folder + \"/\" + f, \"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "        results = pd.DataFrame(data[\"results\"])\n",
    "        for k, v in data[\"meta\"].items():\n",
    "            if not isinstance(v, list):\n",
    "                results[k] = v\n",
    "        results[\"corpus\"] = f.split(\"_\")[0]\n",
    "        results[\"model\"] = f.split(\"_\")[1]\n",
    "        results[\"task\"] = task\n",
    "        if not \"comparison\" in task:\n",
    "            results[\"option_order\"] = \"noOrder\"\n",
    "        if task == \"sentence_comparison\":\n",
    "            results[\"query\"] = \" \".join(f.split(\"q=\")[1].split(\"_\")[0].split(\"+\"))\n",
    "        all_data.append(results)\n",
    "\n",
    "    if all_data == []:\n",
    "        print(f\"No models computed on benchmark {folder} yet!\")\n",
    "        return\n",
    "    df = pd.concat(all_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2986e651-24bf-4ea7-85ce-92fb65d56f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023_results_prompting',\n",
       " 'logprob_critical_word',\n",
       " 'logprobs',\n",
       " 'logprobs_critical_word',\n",
       " 'sentence_comparison',\n",
       " 'sentence_comparison_generation_1vs2',\n",
       " 'sentence_judge',\n",
       " 'sentence_judge_generation_likert',\n",
       " 'word_comparison']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results for all tasks.\n",
    "RESULT_DIR = f\"../results\"\n",
    "TASKS = []\n",
    "for dir_name in os.listdir(RESULT_DIR):\n",
    "    TASKS.append(dir_name)\n",
    "TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e6f253-b676-4c5a-89c9-c28cd46886ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models computed on benchmark ../results/2023_results_prompting yet!\n",
      "No models computed on benchmark ../results/logprob_critical_word yet!\n",
      "No models computed on benchmark ../results/logprobs_critical_word yet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/evlab/ckauf/anaconda310/envs/llm-plaus-prob/lib/python3.10/site-packages/IPython/lib/pretty.py:778: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  output = repr(obj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2023_results_prompting': None,\n",
       " 'logprob_critical_word': None,\n",
       " 'logprobs':      item_id                             good_sentence  \\\n",
       " 0          1                  The actor won the award.   \n",
       " 1          2              The anchorman told the news.   \n",
       " 2          3                The animal found the food.   \n",
       " 3          4               The ant stacked the supply.   \n",
       " 4          5   The archeologist examined the epigraph.   \n",
       " ..       ...                                       ...   \n",
       " 390      393  The witness explained the circumstances.   \n",
       " 391      394           The witness reported the crime.   \n",
       " 392      395                The woman carried the bag.   \n",
       " 393      396                 The woman opened the bag.   \n",
       " 394      397            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence  logprob_of_good_sentence  \\\n",
       " 0              The actor won the battle.                -67.945444   \n",
       " 1        The anchorman told the parable.                -73.403885   \n",
       " 2              The animal found the map.                -69.514266   \n",
       " 3          The ant stacked the suitcase.                -89.358158   \n",
       " 4     The archeologist examined the dog.                -81.993661   \n",
       " ..                                   ...                       ...   \n",
       " 390  The witness explained the equation.                -47.927296   \n",
       " 391      The witness reported the birth.                -45.469055   \n",
       " 392         The woman carried the stone.                -42.243927   \n",
       " 393        The woman opened the manhole.                -41.818043   \n",
       " 394          The woman painted the sign.                -49.418321   \n",
       " \n",
       "      logprob_of_bad_sentence  num_tokens_good_sentence  \\\n",
       " 0                 -71.079809                         9   \n",
       " 1                 -82.829956                        11   \n",
       " 2                 -75.829156                         9   \n",
       " 3                 -87.600263                        10   \n",
       " 4                 -82.412106                        13   \n",
       " ..                       ...                       ...   \n",
       " 390               -52.628216                         8   \n",
       " 391               -50.986553                         8   \n",
       " 392               -43.401520                         8   \n",
       " 393               -47.188039                         8   \n",
       " 394               -44.998878                        10   \n",
       " \n",
       "      num_tokens_bad_sentence                     model  seed eval_type  \\\n",
       " 0                          9  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 1                         12  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 2                          9  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 3                         11  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 4                         11  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " ..                       ...                       ...   ...       ...   \n",
       " 390                        8                    mpt-7b     1    direct   \n",
       " 391                        8                    mpt-7b     1    direct   \n",
       " 392                        8                    mpt-7b     1    direct   \n",
       " 393                        9                    mpt-7b     1    direct   \n",
       " 394                        8                    mpt-7b     1    direct   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " \n",
       "     corpus      task option_order  \n",
       " 0    DTFit  logprobs      noOrder  \n",
       " 1    DTFit  logprobs      noOrder  \n",
       " 2    DTFit  logprobs      noOrder  \n",
       " 3    DTFit  logprobs      noOrder  \n",
       " 4    DTFit  logprobs      noOrder  \n",
       " ..     ...       ...          ...  \n",
       " 390  DTFit  logprobs      noOrder  \n",
       " 391  DTFit  logprobs      noOrder  \n",
       " 392  DTFit  logprobs      noOrder  \n",
       " 393  DTFit  logprobs      noOrder  \n",
       " 394  DTFit  logprobs      noOrder  \n",
       " \n",
       " [2765 rows x 15 columns],\n",
       " 'logprobs_critical_word': None,\n",
       " 'sentence_comparison':      item_id                                        prompt_good  \\\n",
       " 0          1  You evaluating the plausibility of sentences. ...   \n",
       " 1          2  You evaluating the plausibility of sentences. ...   \n",
       " 2          3  You evaluating the plausibility of sentences. ...   \n",
       " 3          4  You evaluating the plausibility of sentences. ...   \n",
       " 4          5  You evaluating the plausibility of sentences. ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  Here are two English sentences:\\n\\n1) The witn...   \n",
       " 391      394  Here are two English sentences:\\n\\n1) The witn...   \n",
       " 392      395  Here are two English sentences:\\n\\n1) The woma...   \n",
       " 393      396  Here are two English sentences:\\n\\n1) The woma...   \n",
       " 394      397  Here are two English sentences:\\n\\n1) The woma...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence good_continuation bad_continuation  \\\n",
       " 0              The actor won the battle.                 2                1   \n",
       " 1        The anchorman told the parable.                 2                1   \n",
       " 2              The animal found the map.                 2                1   \n",
       " 3          The ant stacked the suitcase.                 2                1   \n",
       " 4     The archeologist examined the dog.                 2                1   \n",
       " ..                                   ...               ...              ...   \n",
       " 390  The witness explained the equation.                 1                2   \n",
       " 391      The witness reported the birth.                 1                2   \n",
       " 392         The woman carried the stone.                 1                2   \n",
       " 393        The woman opened the manhole.                 1                2   \n",
       " 394          The woman painted the sign.                 1                2   \n",
       " \n",
       "      logprob_of_good_cont  logprob_of_bad_cont                     model  \\\n",
       " 0               -3.983635            -1.867823  Mistral-7B-Instruct-v0.1   \n",
       " 1               -4.045283            -1.931500  Mistral-7B-Instruct-v0.1   \n",
       " 2               -4.253887            -1.935124  Mistral-7B-Instruct-v0.1   \n",
       " 3               -4.251855            -1.914859  Mistral-7B-Instruct-v0.1   \n",
       " 4               -3.700964            -1.685585  Mistral-7B-Instruct-v0.1   \n",
       " ..                    ...                  ...                       ...   \n",
       " 390             -1.016659            -1.595894                    mpt-7b   \n",
       " 391             -0.977131            -1.676144                    mpt-7b   \n",
       " 392             -0.860074            -1.586995                    mpt-7b   \n",
       " 393             -0.933110            -1.581357                    mpt-7b   \n",
       " 394             -1.020891            -1.604116                    mpt-7b   \n",
       " \n",
       "      seed            eval_type option_order  \\\n",
       " 0       0         metaInstruct     badFirst   \n",
       " 1       0         metaInstruct     badFirst   \n",
       " 2       0         metaInstruct     badFirst   \n",
       " 3       0         metaInstruct     badFirst   \n",
       " 4       0         metaInstruct     badFirst   \n",
       " ..    ...                  ...          ...   \n",
       " 390     1  metaQuestionComplex    goodFirst   \n",
       " 391     1  metaQuestionComplex    goodFirst   \n",
       " 392     1  metaQuestionComplex    goodFirst   \n",
       " 393     1  metaQuestionComplex    goodFirst   \n",
       " 394     1  metaQuestionComplex    goodFirst   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " \n",
       "     corpus                 task         query  \n",
       " 0    DTFit  sentence_comparison  is plausible  \n",
       " 1    DTFit  sentence_comparison  is plausible  \n",
       " 2    DTFit  sentence_comparison  is plausible  \n",
       " 3    DTFit  sentence_comparison  is plausible  \n",
       " 4    DTFit  sentence_comparison  is plausible  \n",
       " ..     ...                  ...           ...  \n",
       " 390  DTFit  sentence_comparison   makes sense  \n",
       " 391  DTFit  sentence_comparison   makes sense  \n",
       " 392  DTFit  sentence_comparison   makes sense  \n",
       " 393  DTFit  sentence_comparison   makes sense  \n",
       " 394  DTFit  sentence_comparison   makes sense  \n",
       " \n",
       " [33180 rows x 17 columns],\n",
       " 'sentence_comparison_generation_1vs2':      item_id                                             prompt  \\\n",
       " 0          1  You will be given two sentences. Your task is ...   \n",
       " 1          2  You will be given two sentences. Your task is ...   \n",
       " 2          3  You will be given two sentences. Your task is ...   \n",
       " 3          4  You will be given two sentences. Your task is ...   \n",
       " 4          5  You will be given two sentences. Your task is ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  You will be given two sentences. Your task is ...   \n",
       " 391      394  You will be given two sentences. Your task is ...   \n",
       " 392      395  You will be given two sentences. Your task is ...   \n",
       " 393      396  You will be given two sentences. Your task is ...   \n",
       " 394      397  You will be given two sentences. Your task is ...   \n",
       " \n",
       "     good_sentence_nr bad_sentence_nr  \\\n",
       " 0                  2               1   \n",
       " 1                  2               1   \n",
       " 2                  2               1   \n",
       " 3                  2               1   \n",
       " 4                  2               1   \n",
       " ..               ...             ...   \n",
       " 390                1               2   \n",
       " 391                1               2   \n",
       " 392                1               2   \n",
       " 393                1               2   \n",
       " 394                1               2   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence  \\\n",
       " 0              The actor won the battle.   \n",
       " 1        The anchorman told the parable.   \n",
       " 2              The animal found the map.   \n",
       " 3          The ant stacked the suitcase.   \n",
       " 4     The archeologist examined the dog.   \n",
       " ..                                   ...   \n",
       " 390  The witness explained the equation.   \n",
       " 391      The witness reported the birth.   \n",
       " 392         The woman carried the stone.   \n",
       " 393        The woman opened the manhole.   \n",
       " 394          The woman painted the sign.   \n",
       " \n",
       "                                             generation  \\\n",
       " 0                                                    2   \n",
       " 1                                                    2   \n",
       " 2                                                    2   \n",
       " 3                                                    2   \n",
       " 4                                                    2   \n",
       " ..                                                 ...   \n",
       " 390  \\n\"\"\"\\n\"The witness explained the circumstance...   \n",
       " 391                                                \\n2   \n",
       " 392                                                      \n",
       " 393                                                      \n",
       " 394                                              \\t2\\n   \n",
       " \n",
       "                         model  seed     gen_type         query option_order  \\\n",
       " 0    Mistral-7B-Instruct-v0.1     0  constrained  is plausible     badFirst   \n",
       " 1    Mistral-7B-Instruct-v0.1     0  constrained  is plausible     badFirst   \n",
       " 2    Mistral-7B-Instruct-v0.1     0  constrained  is plausible     badFirst   \n",
       " 3    Mistral-7B-Instruct-v0.1     0  constrained  is plausible     badFirst   \n",
       " 4    Mistral-7B-Instruct-v0.1     0  constrained  is plausible     badFirst   \n",
       " ..                        ...   ...          ...           ...          ...   \n",
       " 390                    mpt-7b     1         free  is plausible    goodFirst   \n",
       " 391                    mpt-7b     1         free  is plausible    goodFirst   \n",
       " 392                    mpt-7b     1         free  is plausible    goodFirst   \n",
       " 393                    mpt-7b     1         free  is plausible    goodFirst   \n",
       " 394                    mpt-7b     1         free  is plausible    goodFirst   \n",
       " \n",
       "     fullInstruction                                          data_file  \\\n",
       " 0              True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 1              True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 2              True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 3              True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 4              True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " ..              ...                                                ...   \n",
       " 390            True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 391            True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 392            True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 393            True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 394            True  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " \n",
       "                timestamp corpus                                 task  \\\n",
       " 0    2024-01-31 14:55:43  DTFit  sentence_comparison_generation_1vs2   \n",
       " 1    2024-01-31 14:55:43  DTFit  sentence_comparison_generation_1vs2   \n",
       " 2    2024-01-31 14:55:43  DTFit  sentence_comparison_generation_1vs2   \n",
       " 3    2024-01-31 14:55:43  DTFit  sentence_comparison_generation_1vs2   \n",
       " 4    2024-01-31 14:55:43  DTFit  sentence_comparison_generation_1vs2   \n",
       " ..                   ...    ...                                  ...   \n",
       " 390  2024-02-05 00:28:48  DTFit  sentence_comparison_generation_1vs2   \n",
       " 391  2024-02-05 00:28:48  DTFit  sentence_comparison_generation_1vs2   \n",
       " 392  2024-02-05 00:28:48  DTFit  sentence_comparison_generation_1vs2   \n",
       " 393  2024-02-05 00:28:48  DTFit  sentence_comparison_generation_1vs2   \n",
       " 394  2024-02-05 00:28:48  DTFit  sentence_comparison_generation_1vs2   \n",
       " \n",
       "     contains_pattern  \n",
       " 0                NaN  \n",
       " 1                NaN  \n",
       " 2                NaN  \n",
       " 3                NaN  \n",
       " 4                NaN  \n",
       " ..               ...  \n",
       " 390            False  \n",
       " 391             True  \n",
       " 392            False  \n",
       " 393            False  \n",
       " 394             True  \n",
       " \n",
       " [20145 rows x 18 columns],\n",
       " 'sentence_judge':      item_id                                    good_prompt_yes  \\\n",
       " 0          1  Here is a sentence:\\n\\nThe actor won the award...   \n",
       " 1          2  Here is a sentence:\\n\\nThe anchorman told the ...   \n",
       " 2          3  Here is a sentence:\\n\\nThe animal found the fo...   \n",
       " 3          4  Here is a sentence:\\n\\nThe ant stacked the sup...   \n",
       " 4          5  Here is a sentence:\\n\\nThe archeologist examin...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  Here is a sentence:\\n\\nThe witness explained t...   \n",
       " 391      394  Here is a sentence:\\n\\nThe witness reported th...   \n",
       " 392      395  Here is a sentence:\\n\\nThe woman carried the b...   \n",
       " 393      396  Here is a sentence:\\n\\nThe woman opened the ba...   \n",
       " 394      397  Here is a sentence:\\n\\nThe woman painted the t...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence  logprob_of_yes_good_sentence  \\\n",
       " 0              The actor won the battle.                     -0.033269   \n",
       " 1        The anchorman told the parable.                     -0.067229   \n",
       " 2              The animal found the map.                     -0.033161   \n",
       " 3          The ant stacked the suitcase.                     -0.430609   \n",
       " 4     The archeologist examined the dog.                     -0.034161   \n",
       " ..                                   ...                           ...   \n",
       " 390  The witness explained the equation.                     -1.425381   \n",
       " 391      The witness reported the birth.                     -1.444232   \n",
       " 392         The woman carried the stone.                     -1.364215   \n",
       " 393        The woman opened the manhole.                     -1.409248   \n",
       " 394          The woman painted the sign.                     -1.530032   \n",
       " \n",
       "      logprob_of_yes_bad_sentence  logprob_of_no_good_sentence  \\\n",
       " 0                      -0.291937                    -3.739641   \n",
       " 1                      -0.319613                    -2.907173   \n",
       " 2                      -0.543927                    -3.725307   \n",
       " 3                      -1.316217                    -1.098567   \n",
       " 4                      -0.620788                    -3.645984   \n",
       " ..                           ...                          ...   \n",
       " 390                    -1.429461                    -1.281883   \n",
       " 391                    -1.437249                    -1.214092   \n",
       " 392                    -1.338311                    -1.249655   \n",
       " 393                    -1.447602                    -1.242473   \n",
       " 394                    -1.316937                    -1.208182   \n",
       " \n",
       "      logprob_of_no_bad_sentence                     model  seed  \\\n",
       " 0                     -1.444896  Mistral-7B-Instruct-v0.1     0   \n",
       " 1                     -1.349141  Mistral-7B-Instruct-v0.1     0   \n",
       " 2                     -0.915880  Mistral-7B-Instruct-v0.1     0   \n",
       " 3                     -0.333705  Mistral-7B-Instruct-v0.1     0   \n",
       " 4                     -0.809244  Mistral-7B-Instruct-v0.1     0   \n",
       " ..                          ...                       ...   ...   \n",
       " 390                   -1.210486                    mpt-7b     1   \n",
       " 391                   -1.161439                    mpt-7b     1   \n",
       " 392                   -1.224672                    mpt-7b     1   \n",
       " 393                   -1.174122                    mpt-7b     1   \n",
       " 394                   -1.223034                    mpt-7b     1   \n",
       " \n",
       "                eval_type                                          data_file  \\\n",
       " 0    metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 1    metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 2    metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 3    metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 4    metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " ..                   ...                                                ...   \n",
       " 390  metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 391  metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 392  metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 393  metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 394  metaQuestionComplex  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " \n",
       "                timestamp corpus            task option_order  \n",
       " 0    2024-01-31 14:56:41  DTFit  sentence_judge      noOrder  \n",
       " 1    2024-01-31 14:56:41  DTFit  sentence_judge      noOrder  \n",
       " 2    2024-01-31 14:56:41  DTFit  sentence_judge      noOrder  \n",
       " 3    2024-01-31 14:56:41  DTFit  sentence_judge      noOrder  \n",
       " 4    2024-01-31 14:56:41  DTFit  sentence_judge      noOrder  \n",
       " ..                   ...    ...             ...          ...  \n",
       " 390  2024-01-31 18:47:43  DTFit  sentence_judge      noOrder  \n",
       " 391  2024-01-31 18:47:43  DTFit  sentence_judge      noOrder  \n",
       " 392  2024-01-31 18:47:43  DTFit  sentence_judge      noOrder  \n",
       " 393  2024-01-31 18:47:43  DTFit  sentence_judge      noOrder  \n",
       " 394  2024-01-31 18:47:43  DTFit  sentence_judge      noOrder  \n",
       " \n",
       " [6320 rows x 16 columns],\n",
       " 'sentence_judge_generation_likert':      item_id                                        good_prompt  \\\n",
       " 0          1  You will be given a sentence. Your task is to ...   \n",
       " 1          2  You will be given a sentence. Your task is to ...   \n",
       " 2          3  You will be given a sentence. Your task is to ...   \n",
       " 3          4  You will be given a sentence. Your task is to ...   \n",
       " 4          5  You will be given a sentence. Your task is to ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  You will be given a sentence. Your task is to ...   \n",
       " 391      394  You will be given a sentence. Your task is to ...   \n",
       " 392      395  You will be given a sentence. Your task is to ...   \n",
       " 393      396  You will be given a sentence. Your task is to ...   \n",
       " 394      397  You will be given a sentence. Your task is to ...   \n",
       " \n",
       "                                             bad_prompt  \\\n",
       " 0    You will be given a sentence. Your task is to ...   \n",
       " 1    You will be given a sentence. Your task is to ...   \n",
       " 2    You will be given a sentence. Your task is to ...   \n",
       " 3    You will be given a sentence. Your task is to ...   \n",
       " 4    You will be given a sentence. Your task is to ...   \n",
       " ..                                                 ...   \n",
       " 390  You will be given a sentence. Your task is to ...   \n",
       " 391  You will be given a sentence. Your task is to ...   \n",
       " 392  You will be given a sentence. Your task is to ...   \n",
       " 393  You will be given a sentence. Your task is to ...   \n",
       " 394  You will be given a sentence. Your task is to ...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence good_generation bad_generation  \\\n",
       " 0              The actor won the battle.               6              4   \n",
       " 1        The anchorman told the parable.               7              5   \n",
       " 2              The animal found the map.               6              5   \n",
       " 3          The ant stacked the suitcase.               6              2   \n",
       " 4     The archeologist examined the dog.               6              5   \n",
       " ..                                   ...             ...            ...   \n",
       " 390  The witness explained the equation.               5              4   \n",
       " 391      The witness reported the birth.               1              3   \n",
       " 392         The woman carried the stone.               4              6   \n",
       " 393        The woman opened the manhole.               5              3   \n",
       " 394          The woman painted the sign.               6              3   \n",
       " \n",
       "                         model  seed     gen_type         query  \\\n",
       " 0    Mistral-7B-Instruct-v0.1     0  constrained  is plausible   \n",
       " 1    Mistral-7B-Instruct-v0.1     0  constrained  is plausible   \n",
       " 2    Mistral-7B-Instruct-v0.1     0  constrained  is plausible   \n",
       " 3    Mistral-7B-Instruct-v0.1     0  constrained  is plausible   \n",
       " 4    Mistral-7B-Instruct-v0.1     0  constrained  is plausible   \n",
       " ..                        ...   ...          ...           ...   \n",
       " 390                    mpt-7b     1  constrained  is plausible   \n",
       " 391                    mpt-7b     1  constrained  is plausible   \n",
       " 392                    mpt-7b     1  constrained  is plausible   \n",
       " 393                    mpt-7b     1  constrained  is plausible   \n",
       " 394                    mpt-7b     1  constrained  is plausible   \n",
       " \n",
       "     fullInstruction                                          data_file  \\\n",
       " 0              None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 1              None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 2              None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 3              None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 4              None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " ..              ...                                                ...   \n",
       " 390            None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 391            None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 392            None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 393            None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " 394            None  /net/vast-storage.ib.cluster/scratch/vast/evla...   \n",
       " \n",
       "                timestamp corpus                              task  \\\n",
       " 0    2024-01-31 14:55:36  DTFit  sentence_judge_generation_likert   \n",
       " 1    2024-01-31 14:55:36  DTFit  sentence_judge_generation_likert   \n",
       " 2    2024-01-31 14:55:36  DTFit  sentence_judge_generation_likert   \n",
       " 3    2024-01-31 14:55:36  DTFit  sentence_judge_generation_likert   \n",
       " 4    2024-01-31 14:55:36  DTFit  sentence_judge_generation_likert   \n",
       " ..                   ...    ...                               ...   \n",
       " 390  2024-02-12 20:47:58  DTFit  sentence_judge_generation_likert   \n",
       " 391  2024-02-12 20:47:58  DTFit  sentence_judge_generation_likert   \n",
       " 392  2024-02-12 20:47:58  DTFit  sentence_judge_generation_likert   \n",
       " 393  2024-02-12 20:47:58  DTFit  sentence_judge_generation_likert   \n",
       " 394  2024-02-12 20:47:58  DTFit  sentence_judge_generation_likert   \n",
       " \n",
       "     option_order good_continuation_contains_pattern  \\\n",
       " 0        noOrder                                NaN   \n",
       " 1        noOrder                                NaN   \n",
       " 2        noOrder                                NaN   \n",
       " 3        noOrder                                NaN   \n",
       " 4        noOrder                                NaN   \n",
       " ..           ...                                ...   \n",
       " 390      noOrder                                NaN   \n",
       " 391      noOrder                                NaN   \n",
       " 392      noOrder                                NaN   \n",
       " 393      noOrder                                NaN   \n",
       " 394      noOrder                                NaN   \n",
       " \n",
       "     bad_continuation_contains_pattern  \n",
       " 0                                 NaN  \n",
       " 1                                 NaN  \n",
       " 2                                 NaN  \n",
       " 3                                 NaN  \n",
       " 4                                 NaN  \n",
       " ..                                ...  \n",
       " 390                               NaN  \n",
       " 391                               NaN  \n",
       " 392                               NaN  \n",
       " 393                               NaN  \n",
       " 394                               NaN  \n",
       " \n",
       " [9480 rows x 19 columns],\n",
       " 'word_comparison':      item_id                                        prompt_good  \\\n",
       " 0          1  Here is the beginning of an English sentence: ...   \n",
       " 1          2  Here is the beginning of an English sentence: ...   \n",
       " 2          3  Here is the beginning of an English sentence: ...   \n",
       " 3          4  Here is the beginning of an English sentence: ...   \n",
       " 4          5  Here is the beginning of an English sentence: ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  Here is the beginning of an English sentence: ...   \n",
       " 391      394  Here is the beginning of an English sentence: ...   \n",
       " 392      395  Here is the beginning of an English sentence: ...   \n",
       " 393      396  Here is the beginning of an English sentence: ...   \n",
       " 394      397  Here is the beginning of an English sentence: ...   \n",
       " \n",
       "                             prefix good_continuation bad_continuation  \\\n",
       " 0                The actor won the             award           battle   \n",
       " 1           The anchorman told the              news          parable   \n",
       " 2             The animal found the              food              map   \n",
       " 3              The ant stacked the            supply         suitcase   \n",
       " 4    The archeologist examined the          epigraph              dog   \n",
       " ..                             ...               ...              ...   \n",
       " 390      The witness explained the     circumstances         equation   \n",
       " 391       The witness reported the             crime            birth   \n",
       " 392          The woman carried the               bag            stone   \n",
       " 393           The woman opened the               bag          manhole   \n",
       " 394          The woman painted the           toenail             sign   \n",
       " \n",
       "      logprob_of_good_cont  logprob_of_bad_cont                     model  \\\n",
       " 0               -0.079091           -10.199320  Mistral-7B-Instruct-v0.1   \n",
       " 1               -0.094156            -0.000327  Mistral-7B-Instruct-v0.1   \n",
       " 2               -0.126093            -6.323389  Mistral-7B-Instruct-v0.1   \n",
       " 3               -0.103613            -0.000022  Mistral-7B-Instruct-v0.1   \n",
       " 4               -0.000040            -9.110038  Mistral-7B-Instruct-v0.1   \n",
       " ..                    ...                  ...                       ...   \n",
       " 390             -1.285732            -1.796547                    mpt-7b   \n",
       " 391             -0.894202            -2.254706                    mpt-7b   \n",
       " 392             -1.082203            -2.109519                    mpt-7b   \n",
       " 393             -1.017724            -1.919083                    mpt-7b   \n",
       " 394             -1.758381            -1.283579                    mpt-7b   \n",
       " \n",
       "      seed            eval_type option_order  \\\n",
       " 0       0  metaQuestionComplex     badFirst   \n",
       " 1       0  metaQuestionComplex     badFirst   \n",
       " 2       0  metaQuestionComplex     badFirst   \n",
       " 3       0  metaQuestionComplex     badFirst   \n",
       " 4       0  metaQuestionComplex     badFirst   \n",
       " ..    ...                  ...          ...   \n",
       " 390     1  metaQuestionComplex    goodFirst   \n",
       " 391     1  metaQuestionComplex    goodFirst   \n",
       " 392     1  metaQuestionComplex    goodFirst   \n",
       " 393     1  metaQuestionComplex    goodFirst   \n",
       " 394     1  metaQuestionComplex    goodFirst   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:09   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:09   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:09   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:09   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:09   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:27   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:27   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:27   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:27   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-06 22:55:27   \n",
       " \n",
       "     corpus             task  \n",
       " 0    DTFit  word_comparison  \n",
       " 1    DTFit  word_comparison  \n",
       " 2    DTFit  word_comparison  \n",
       " 3    DTFit  word_comparison  \n",
       " 4    DTFit  word_comparison  \n",
       " ..     ...              ...  \n",
       " 390  DTFit  word_comparison  \n",
       " 391  DTFit  word_comparison  \n",
       " 392  DTFit  word_comparison  \n",
       " 393  DTFit  word_comparison  \n",
       " 394  DTFit  word_comparison  \n",
       " \n",
       " [11060 rows x 15 columns]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS = {task: read_data(f\"{RESULT_DIR}/{task}\") for task in TASKS}\n",
    "RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fe6f2-cd49-4691-a76e-28a0b6082647",
   "metadata": {},
   "source": [
    "# Plot for one dataset logprobs vs. other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c602e828-33a0-48f0-b6f5-8ca15af04994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_single_number(input_string):\n",
    "    # Find all sequences of digits in the string\n",
    "    numbers = re.findall(r'\\d+', input_string)\n",
    "\n",
    "    # Return the single number or None if there are multiple numbers\n",
    "    return numbers[0] if len(numbers) == 1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d231ddd6-fcb8-449e-866b-a7e94b28b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_free_generation_dfs(free_df, task):\n",
    "    filtered_df = free_df.copy()\n",
    "\n",
    "    if task == \"sentence_comparison_generation_1vs2\":\n",
    "        # subset to see if it contains continuation\n",
    "        filtered_df = filtered_df[(filtered_df[\"contains_pattern\"] == True)]\n",
    "        filtered_df['generation'] = filtered_df['generation'].apply(extract_single_number)\n",
    "        filtered_df = filtered_df[filtered_df['generation'].notna()]\n",
    "    else:\n",
    "        try:\n",
    "            # subset to see if it contains continuation\n",
    "            filtered_df = filtered_df[(filtered_df[\"bad_continuation_contains_pattern\"] == True) & \\\n",
    "                                      (filtered_df[\"good_continuation_contains_pattern\"] == True)]\n",
    "            filtered_df['good_generation'] = filtered_df['good_generation'].apply(extract_single_number)\n",
    "            filtered_df['bad_generation'] = filtered_df['bad_generation'].apply(extract_single_number)\n",
    "            filtered_df = filtered_df[(filtered_df['good_generation'].notna()) & \\\n",
    "                                      (filtered_df['bad_generation'].notna())]\n",
    "        except:\n",
    "            filtered_df['good_generation'] = filtered_df['good_generation'].apply(extract_single_number)\n",
    "            filtered_df['bad_generation'] = filtered_df['bad_generation'].apply(extract_single_number)\n",
    "            filtered_df = filtered_df[(filtered_df['good_generation'].notna()) & \\\n",
    "                                      (filtered_df['bad_generation'].notna())]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        print(\"WATCH OUT!! Filtering resulted in no values\")\n",
    "        \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7331f80f-0ff9-4357-89ef-f6d5f9dfa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_metric(result_df, task):\n",
    "    out_df = result_df.copy()\n",
    "    initial_length = len(out_df)\n",
    "    # Drop empty columns\n",
    "    out_df = out_df.dropna(axis=1, how='all')\n",
    "    # Drop empty rows\n",
    "    out_df = out_df.dropna(axis=0, how='all')\n",
    "    after_drop_length = len(out_df)\n",
    "    if initial_length - after_drop_length != 0:\n",
    "        print(f\"Dropped {initial_length - after_drop_length} rows with NA values\")\n",
    "\n",
    "    # Balanced accuracy: (TPR+TNR)/2\n",
    "    def _balanced_accuracy(rows):\n",
    "        tp = rows.model_prefers_yes_good.mean()\n",
    "        tn = rows.model_prefers_no_bad.mean()\n",
    "        return np.mean([tp, tn])\n",
    "    \n",
    "    if task == \"logprobs\":\n",
    "        out_df[\"Accuracy\"] = out_df.apply(\n",
    "            lambda row: 1 if row.logprob_of_good_sentence > row.logprob_of_bad_sentence else 0, axis=1)\n",
    "\n",
    "    elif task == \"logprobs_cricital_word\":\n",
    "        raise NotImplementedError(\"Not for this task\")\n",
    "    \n",
    "    elif task == \"sentence_judge\": #continuation here is \"yes\"/\"no\"\n",
    "        # True positive\n",
    "        out_df[\"model_prefers_yes_good\"] = out_df.apply(\n",
    "            lambda row: row.logprob_of_yes_good_sentence > row.logprob_of_no_good_sentence,\n",
    "            axis=1\n",
    "        )\n",
    "        # True negative\n",
    "        out_df[\"model_prefers_no_bad\"] = out_df.apply(\n",
    "            lambda row: row.logprob_of_no_bad_sentence > row.logprob_of_yes_bad_sentence,\n",
    "            axis=1\n",
    "        )\n",
    "        # False positive\n",
    "        out_df[\"model_prefers_yes_bad\"] = out_df.apply(\n",
    "            lambda row: row.logprob_of_yes_bad_sentence > row.logprob_of_no_bad_sentence,\n",
    "            axis=1\n",
    "        )\n",
    "        # False negative\n",
    "        out_df[\"model_prefers_no_good\"] = out_df.apply(\n",
    "            lambda row: row.logprob_of_no_good_sentence > row.logprob_of_yes_good_sentence,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        out_df[\"Accuracy\"] = out_df.apply(\n",
    "            lambda row: 1 if ((row.model_prefers_yes_good == 1) & (row.model_prefers_no_bad == 1)) else 0, axis=1)\n",
    "        \n",
    "\n",
    "    elif task == \"sentence_comparison\": #continuation here is \"1\"/\"2\" #note I messed up here with the task;\n",
    "        # that's why the two cases, fix this in the jsons\n",
    "        try:\n",
    "            out_df[\"Accuracy\"] = out_df.apply(\n",
    "                lambda row: 1 if row.logprob_of_good_continuation > row.logprob_of_bad_continuation else 0, axis=1)\n",
    "        except:\n",
    "            out_df[\"Accuracy\"] = out_df.apply(\n",
    "                lambda row: 1 if row.logprob_of_good_cont > row.logprob_of_bad_cont else 0, axis=1)\n",
    "\n",
    "    elif task == \"sentence_comparison_generation_1vs2\":\n",
    "        if \"free\" in out_df.gen_type.unique():\n",
    "            free_df = out_df[out_df.gen_type == \"free\"]\n",
    "            free_df = preprocess_free_generation_dfs(free_df, task)\n",
    "            constrained_df = out_df[out_df.gen_type == \"constrained\"]\n",
    "            out_df = pd.concat([free_df, constrained_df])\n",
    "        if len(out_df) == 0:\n",
    "            print(\"Filtering resulted in no values\")\n",
    "        else:\n",
    "            out_df[\"Accuracy\"] = out_df.apply(\n",
    "                lambda row: 1 if row.generation == row.good_sentence_nr else 0, axis=1)\n",
    "\n",
    "    elif task == \"sentence_judge_generation_likert\":\n",
    "        if \"free\" in out_df.gen_type.unique():\n",
    "            free_df = out_df[out_df.gen_type == \"free\"]\n",
    "            free_df = preprocess_free_generation_dfs(free_df, task)\n",
    "            constrained_df = out_df[out_df.gen_type == \"constrained\"]\n",
    "            out_df = pd.concat([free_df, constrained_df])\n",
    "        if len(out_df) == 0:\n",
    "            print(\"Filtering resulted in no values\")\n",
    "        else:\n",
    "            out_df[\"Accuracy\"] = out_df.apply(\n",
    "                lambda row: 1 if row.good_generation > row.bad_generation else 0, axis=1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Not implemented\")\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be0362c-55d0-4adc-bf17-b7832195f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs\n",
      "****\n",
      "sentence_comparison\n",
      "****\n",
      "sentence_judge\n",
      "****\n",
      "sentence_judge_generation_likert\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for task, result_df in RESULTS.items():\n",
    "    if not task in task_order:\n",
    "        continue\n",
    "    if result_df is None:\n",
    "        continue\n",
    "    print(task)\n",
    "    result_df = result_df[result_df.corpus == DATASET]\n",
    "    result_df = result_df[result_df.model.isin(MODEL_LIST)]\n",
    "    if len(result_df) == 0:\n",
    "        print(f\"{DATASET} was not computed for task {task} yet\")\n",
    "        continue\n",
    "    out_df = compute_accuracy_metric(result_df, task)\n",
    "    df_list.append(out_df)\n",
    "    print(\"****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1fbf65d-2481-4013-a005-a8a25792f1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     item_id                             good_sentence  \\\n",
       " 0          1                  The actor won the award.   \n",
       " 1          2              The anchorman told the news.   \n",
       " 2          3                The animal found the food.   \n",
       " 3          4               The ant stacked the supply.   \n",
       " 4          5   The archeologist examined the epigraph.   \n",
       " ..       ...                                       ...   \n",
       " 390      393  The witness explained the circumstances.   \n",
       " 391      394           The witness reported the crime.   \n",
       " 392      395                The woman carried the bag.   \n",
       " 393      396                 The woman opened the bag.   \n",
       " 394      397            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence  logprob_of_good_sentence  \\\n",
       " 0              The actor won the battle.                -67.945444   \n",
       " 1        The anchorman told the parable.                -73.403885   \n",
       " 2              The animal found the map.                -69.514266   \n",
       " 3          The ant stacked the suitcase.                -89.358158   \n",
       " 4     The archeologist examined the dog.                -81.993661   \n",
       " ..                                   ...                       ...   \n",
       " 390  The witness explained the equation.                -47.927296   \n",
       " 391      The witness reported the birth.                -45.469055   \n",
       " 392         The woman carried the stone.                -42.243927   \n",
       " 393        The woman opened the manhole.                -41.818043   \n",
       " 394          The woman painted the sign.                -49.418321   \n",
       " \n",
       "      logprob_of_bad_sentence  num_tokens_good_sentence  \\\n",
       " 0                 -71.079809                         9   \n",
       " 1                 -82.829956                        11   \n",
       " 2                 -75.829156                         9   \n",
       " 3                 -87.600263                        10   \n",
       " 4                 -82.412106                        13   \n",
       " ..                       ...                       ...   \n",
       " 390               -52.628216                         8   \n",
       " 391               -50.986553                         8   \n",
       " 392               -43.401520                         8   \n",
       " 393               -47.188039                         8   \n",
       " 394               -44.998878                        10   \n",
       " \n",
       "      num_tokens_bad_sentence                     model  seed eval_type  \\\n",
       " 0                          9  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 1                         12  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 2                          9  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 3                         11  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " 4                         11  Mistral-7B-Instruct-v0.1     1    direct   \n",
       " ..                       ...                       ...   ...       ...   \n",
       " 390                        8                    mpt-7b     1    direct   \n",
       " 391                        8                    mpt-7b     1    direct   \n",
       " 392                        8                    mpt-7b     1    direct   \n",
       " 393                        9                    mpt-7b     1    direct   \n",
       " 394                        8                    mpt-7b     1    direct   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:41:04   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-03 00:42:07   \n",
       " \n",
       "     corpus      task option_order  Accuracy  \n",
       " 0    DTFit  logprobs      noOrder         1  \n",
       " 1    DTFit  logprobs      noOrder         1  \n",
       " 2    DTFit  logprobs      noOrder         1  \n",
       " 3    DTFit  logprobs      noOrder         0  \n",
       " 4    DTFit  logprobs      noOrder         1  \n",
       " ..     ...       ...          ...       ...  \n",
       " 390  DTFit  logprobs      noOrder         1  \n",
       " 391  DTFit  logprobs      noOrder         1  \n",
       " 392  DTFit  logprobs      noOrder         1  \n",
       " 393  DTFit  logprobs      noOrder         1  \n",
       " 394  DTFit  logprobs      noOrder         0  \n",
       " \n",
       " [2765 rows x 16 columns],\n",
       "      item_id                                        prompt_good  \\\n",
       " 0          1  You evaluating the plausibility of sentences. ...   \n",
       " 1          2  You evaluating the plausibility of sentences. ...   \n",
       " 2          3  You evaluating the plausibility of sentences. ...   \n",
       " 3          4  You evaluating the plausibility of sentences. ...   \n",
       " 4          5  You evaluating the plausibility of sentences. ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  Here are two English sentences:\\n\\n1) The witn...   \n",
       " 391      394  Here are two English sentences:\\n\\n1) The witn...   \n",
       " 392      395  Here are two English sentences:\\n\\n1) The woma...   \n",
       " 393      396  Here are two English sentences:\\n\\n1) The woma...   \n",
       " 394      397  Here are two English sentences:\\n\\n1) The woma...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence good_continuation bad_continuation  \\\n",
       " 0              The actor won the battle.                 2                1   \n",
       " 1        The anchorman told the parable.                 2                1   \n",
       " 2              The animal found the map.                 2                1   \n",
       " 3          The ant stacked the suitcase.                 2                1   \n",
       " 4     The archeologist examined the dog.                 2                1   \n",
       " ..                                   ...               ...              ...   \n",
       " 390  The witness explained the equation.                 1                2   \n",
       " 391      The witness reported the birth.                 1                2   \n",
       " 392         The woman carried the stone.                 1                2   \n",
       " 393        The woman opened the manhole.                 1                2   \n",
       " 394          The woman painted the sign.                 1                2   \n",
       " \n",
       "      logprob_of_good_cont  logprob_of_bad_cont                     model  \\\n",
       " 0               -3.983635            -1.867823  Mistral-7B-Instruct-v0.1   \n",
       " 1               -4.045283            -1.931500  Mistral-7B-Instruct-v0.1   \n",
       " 2               -4.253887            -1.935124  Mistral-7B-Instruct-v0.1   \n",
       " 3               -4.251855            -1.914859  Mistral-7B-Instruct-v0.1   \n",
       " 4               -3.700964            -1.685585  Mistral-7B-Instruct-v0.1   \n",
       " ..                    ...                  ...                       ...   \n",
       " 390             -1.016659            -1.595894                    mpt-7b   \n",
       " 391             -0.977131            -1.676144                    mpt-7b   \n",
       " 392             -0.860074            -1.586995                    mpt-7b   \n",
       " 393             -0.933110            -1.581357                    mpt-7b   \n",
       " 394             -1.020891            -1.604116                    mpt-7b   \n",
       " \n",
       "      seed            eval_type option_order  \\\n",
       " 0       0         metaInstruct     badFirst   \n",
       " 1       0         metaInstruct     badFirst   \n",
       " 2       0         metaInstruct     badFirst   \n",
       " 3       0         metaInstruct     badFirst   \n",
       " 4       0         metaInstruct     badFirst   \n",
       " ..    ...                  ...          ...   \n",
       " 390     1  metaQuestionComplex    goodFirst   \n",
       " 391     1  metaQuestionComplex    goodFirst   \n",
       " 392     1  metaQuestionComplex    goodFirst   \n",
       " 393     1  metaQuestionComplex    goodFirst   \n",
       " 394     1  metaQuestionComplex    goodFirst   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-07 00:05:37   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-11 21:56:57   \n",
       " \n",
       "     corpus                 task         query  Accuracy  \n",
       " 0    DTFit  sentence_comparison  is plausible         0  \n",
       " 1    DTFit  sentence_comparison  is plausible         0  \n",
       " 2    DTFit  sentence_comparison  is plausible         0  \n",
       " 3    DTFit  sentence_comparison  is plausible         0  \n",
       " 4    DTFit  sentence_comparison  is plausible         0  \n",
       " ..     ...                  ...           ...       ...  \n",
       " 390  DTFit  sentence_comparison   makes sense         1  \n",
       " 391  DTFit  sentence_comparison   makes sense         1  \n",
       " 392  DTFit  sentence_comparison   makes sense         1  \n",
       " 393  DTFit  sentence_comparison   makes sense         1  \n",
       " 394  DTFit  sentence_comparison   makes sense         1  \n",
       " \n",
       " [33180 rows x 18 columns],\n",
       "      item_id                                    good_prompt_yes  \\\n",
       " 0          1  Here is a sentence:\\n\\nThe actor won the award...   \n",
       " 1          2  Here is a sentence:\\n\\nThe anchorman told the ...   \n",
       " 2          3  Here is a sentence:\\n\\nThe animal found the fo...   \n",
       " 3          4  Here is a sentence:\\n\\nThe ant stacked the sup...   \n",
       " 4          5  Here is a sentence:\\n\\nThe archeologist examin...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  Here is a sentence:\\n\\nThe witness explained t...   \n",
       " 391      394  Here is a sentence:\\n\\nThe witness reported th...   \n",
       " 392      395  Here is a sentence:\\n\\nThe woman carried the b...   \n",
       " 393      396  Here is a sentence:\\n\\nThe woman opened the ba...   \n",
       " 394      397  Here is a sentence:\\n\\nThe woman painted the t...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence  logprob_of_yes_good_sentence  \\\n",
       " 0              The actor won the battle.                     -0.033269   \n",
       " 1        The anchorman told the parable.                     -0.067229   \n",
       " 2              The animal found the map.                     -0.033161   \n",
       " 3          The ant stacked the suitcase.                     -0.430609   \n",
       " 4     The archeologist examined the dog.                     -0.034161   \n",
       " ..                                   ...                           ...   \n",
       " 390  The witness explained the equation.                     -1.425381   \n",
       " 391      The witness reported the birth.                     -1.444232   \n",
       " 392         The woman carried the stone.                     -1.364215   \n",
       " 393        The woman opened the manhole.                     -1.409248   \n",
       " 394          The woman painted the sign.                     -1.530032   \n",
       " \n",
       "      logprob_of_yes_bad_sentence  logprob_of_no_good_sentence  \\\n",
       " 0                      -0.291937                    -3.739641   \n",
       " 1                      -0.319613                    -2.907173   \n",
       " 2                      -0.543927                    -3.725307   \n",
       " 3                      -1.316217                    -1.098567   \n",
       " 4                      -0.620788                    -3.645984   \n",
       " ..                           ...                          ...   \n",
       " 390                    -1.429461                    -1.281883   \n",
       " 391                    -1.437249                    -1.214092   \n",
       " 392                    -1.338311                    -1.249655   \n",
       " 393                    -1.447602                    -1.242473   \n",
       " 394                    -1.316937                    -1.208182   \n",
       " \n",
       "      logprob_of_no_bad_sentence                     model  seed  ...  \\\n",
       " 0                     -1.444896  Mistral-7B-Instruct-v0.1     0  ...   \n",
       " 1                     -1.349141  Mistral-7B-Instruct-v0.1     0  ...   \n",
       " 2                     -0.915880  Mistral-7B-Instruct-v0.1     0  ...   \n",
       " 3                     -0.333705  Mistral-7B-Instruct-v0.1     0  ...   \n",
       " 4                     -0.809244  Mistral-7B-Instruct-v0.1     0  ...   \n",
       " ..                          ...                       ...   ...  ...   \n",
       " 390                   -1.210486                    mpt-7b     1  ...   \n",
       " 391                   -1.161439                    mpt-7b     1  ...   \n",
       " 392                   -1.224672                    mpt-7b     1  ...   \n",
       " 393                   -1.174122                    mpt-7b     1  ...   \n",
       " 394                   -1.223034                    mpt-7b     1  ...   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:56:41   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:56:41   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:56:41   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:56:41   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:56:41   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 18:47:43   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 18:47:43   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 18:47:43   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 18:47:43   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 18:47:43   \n",
       " \n",
       "     corpus            task option_order model_prefers_yes_good  \\\n",
       " 0    DTFit  sentence_judge      noOrder                   True   \n",
       " 1    DTFit  sentence_judge      noOrder                   True   \n",
       " 2    DTFit  sentence_judge      noOrder                   True   \n",
       " 3    DTFit  sentence_judge      noOrder                   True   \n",
       " 4    DTFit  sentence_judge      noOrder                   True   \n",
       " ..     ...             ...          ...                    ...   \n",
       " 390  DTFit  sentence_judge      noOrder                  False   \n",
       " 391  DTFit  sentence_judge      noOrder                  False   \n",
       " 392  DTFit  sentence_judge      noOrder                  False   \n",
       " 393  DTFit  sentence_judge      noOrder                  False   \n",
       " 394  DTFit  sentence_judge      noOrder                  False   \n",
       " \n",
       "      model_prefers_no_bad  model_prefers_yes_bad  model_prefers_no_good  \\\n",
       " 0                   False                   True                  False   \n",
       " 1                   False                   True                  False   \n",
       " 2                   False                   True                  False   \n",
       " 3                    True                  False                  False   \n",
       " 4                   False                   True                  False   \n",
       " ..                    ...                    ...                    ...   \n",
       " 390                  True                  False                   True   \n",
       " 391                  True                  False                   True   \n",
       " 392                  True                  False                   True   \n",
       " 393                  True                  False                   True   \n",
       " 394                  True                  False                   True   \n",
       " \n",
       "      Accuracy  \n",
       " 0           0  \n",
       " 1           0  \n",
       " 2           0  \n",
       " 3           1  \n",
       " 4           0  \n",
       " ..        ...  \n",
       " 390         0  \n",
       " 391         0  \n",
       " 392         0  \n",
       " 393         0  \n",
       " 394         0  \n",
       " \n",
       " [6320 rows x 21 columns],\n",
       "      item_id                                        good_prompt  \\\n",
       " 0          1  You will be given a sentence. Your task is to ...   \n",
       " 1          2  You will be given a sentence. Your task is to ...   \n",
       " 2          3  You will be given a sentence. Your task is to ...   \n",
       " 3          4  You will be given a sentence. Your task is to ...   \n",
       " 4          5  You will be given a sentence. Your task is to ...   \n",
       " ..       ...                                                ...   \n",
       " 390      393  You will be given a sentence. Your task is to ...   \n",
       " 391      394  You will be given a sentence. Your task is to ...   \n",
       " 392      395  You will be given a sentence. Your task is to ...   \n",
       " 393      396  You will be given a sentence. Your task is to ...   \n",
       " 394      397  You will be given a sentence. Your task is to ...   \n",
       " \n",
       "                                             bad_prompt  \\\n",
       " 0    You will be given a sentence. Your task is to ...   \n",
       " 1    You will be given a sentence. Your task is to ...   \n",
       " 2    You will be given a sentence. Your task is to ...   \n",
       " 3    You will be given a sentence. Your task is to ...   \n",
       " 4    You will be given a sentence. Your task is to ...   \n",
       " ..                                                 ...   \n",
       " 390  You will be given a sentence. Your task is to ...   \n",
       " 391  You will be given a sentence. Your task is to ...   \n",
       " 392  You will be given a sentence. Your task is to ...   \n",
       " 393  You will be given a sentence. Your task is to ...   \n",
       " 394  You will be given a sentence. Your task is to ...   \n",
       " \n",
       "                                 good_sentence  \\\n",
       " 0                    The actor won the award.   \n",
       " 1                The anchorman told the news.   \n",
       " 2                  The animal found the food.   \n",
       " 3                 The ant stacked the supply.   \n",
       " 4     The archeologist examined the epigraph.   \n",
       " ..                                        ...   \n",
       " 390  The witness explained the circumstances.   \n",
       " 391           The witness reported the crime.   \n",
       " 392                The woman carried the bag.   \n",
       " 393                 The woman opened the bag.   \n",
       " 394            The woman painted the toenail.   \n",
       " \n",
       "                             bad_sentence good_generation bad_generation  \\\n",
       " 0              The actor won the battle.               6              2   \n",
       " 1        The anchorman told the parable.               7              5   \n",
       " 2              The animal found the map.               5              4   \n",
       " 3          The ant stacked the suitcase.               6              3   \n",
       " 4     The archeologist examined the dog.               6              2   \n",
       " ..                                   ...             ...            ...   \n",
       " 390  The witness explained the equation.               5              4   \n",
       " 391      The witness reported the birth.               1              3   \n",
       " 392         The woman carried the stone.               4              6   \n",
       " 393        The woman opened the manhole.               5              3   \n",
       " 394          The woman painted the sign.               6              3   \n",
       " \n",
       "                         model  seed     gen_type         query  \\\n",
       " 0    Mistral-7B-Instruct-v0.1     0         free  is plausible   \n",
       " 1    Mistral-7B-Instruct-v0.1     0         free  is plausible   \n",
       " 2    Mistral-7B-Instruct-v0.1     0         free  is plausible   \n",
       " 3    Mistral-7B-Instruct-v0.1     0         free  is plausible   \n",
       " 4    Mistral-7B-Instruct-v0.1     0         free  is plausible   \n",
       " ..                        ...   ...          ...           ...   \n",
       " 390                    mpt-7b     1  constrained  is plausible   \n",
       " 391                    mpt-7b     1  constrained  is plausible   \n",
       " 392                    mpt-7b     1  constrained  is plausible   \n",
       " 393                    mpt-7b     1  constrained  is plausible   \n",
       " 394                    mpt-7b     1  constrained  is plausible   \n",
       " \n",
       "                                              data_file            timestamp  \\\n",
       " 0    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:55:34   \n",
       " 1    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:55:34   \n",
       " 2    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:55:34   \n",
       " 3    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:55:34   \n",
       " 4    /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-01-31 14:55:34   \n",
       " ..                                                 ...                  ...   \n",
       " 390  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-12 20:47:58   \n",
       " 391  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-12 20:47:58   \n",
       " 392  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-12 20:47:58   \n",
       " 393  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-12 20:47:58   \n",
       " 394  /net/vast-storage.ib.cluster/scratch/vast/evla...  2024-02-12 20:47:58   \n",
       " \n",
       "     corpus                              task option_order  \\\n",
       " 0    DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 1    DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 2    DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 3    DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 4    DTFit  sentence_judge_generation_likert      noOrder   \n",
       " ..     ...                               ...          ...   \n",
       " 390  DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 391  DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 392  DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 393  DTFit  sentence_judge_generation_likert      noOrder   \n",
       " 394  DTFit  sentence_judge_generation_likert      noOrder   \n",
       " \n",
       "     good_continuation_contains_pattern bad_continuation_contains_pattern  \\\n",
       " 0                                 True                              True   \n",
       " 1                                 True                              True   \n",
       " 2                                 True                              True   \n",
       " 3                                 True                              True   \n",
       " 4                                 True                              True   \n",
       " ..                                 ...                               ...   \n",
       " 390                                NaN                               NaN   \n",
       " 391                                NaN                               NaN   \n",
       " 392                                NaN                               NaN   \n",
       " 393                                NaN                               NaN   \n",
       " 394                                NaN                               NaN   \n",
       " \n",
       "      Accuracy  \n",
       " 0           1  \n",
       " 1           1  \n",
       " 2           1  \n",
       " 3           1  \n",
       " 4           1  \n",
       " ..        ...  \n",
       " 390         1  \n",
       " 391         0  \n",
       " 392         0  \n",
       " 393         1  \n",
       " 394         1  \n",
       " \n",
       " [7665 rows x 19 columns]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b78e83f-9e93-442b-becc-0fa0ea96c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = []\n",
    "for df in df_list:\n",
    "    #print(df.head())\n",
    "    keep_columns = [\"corpus\", \"model\", \"task\", \"eval_type\", \"gen_type\", \"query\", \"option_order\", \"Accuracy\", \"seed\"]\n",
    "    plot_df = df[[c for c in keep_columns if c in df.columns]]\n",
    "    # print(plot_df.head())\n",
    "    plot_dfs.append(plot_df)\n",
    "len(plot_dfs)\n",
    "full_df = pd.concat(plot_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076ad73c-ac6a-4f85-b17e-dac5cd235b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>option_order</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>seed</th>\n",
       "      <th>query</th>\n",
       "      <th>gen_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49930 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    corpus                     model                              task  \\\n",
       "0    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "1    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "2    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "3    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "4    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "..     ...                       ...                               ...   \n",
       "390  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "391  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "392  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "393  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "394  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "\n",
       "    eval_type option_order  Accuracy  seed         query     gen_type  \n",
       "0      direct      noOrder         1     1           NaN          NaN  \n",
       "1      direct      noOrder         1     1           NaN          NaN  \n",
       "2      direct      noOrder         1     1           NaN          NaN  \n",
       "3      direct      noOrder         0     1           NaN          NaN  \n",
       "4      direct      noOrder         1     1           NaN          NaN  \n",
       "..        ...          ...       ...   ...           ...          ...  \n",
       "390       NaN      noOrder         1     1  is plausible  constrained  \n",
       "391       NaN      noOrder         0     1  is plausible  constrained  \n",
       "392       NaN      noOrder         0     1  is plausible  constrained  \n",
       "393       NaN      noOrder         1     1  is plausible  constrained  \n",
       "394       NaN      noOrder         1     1  is plausible  constrained  \n",
       "\n",
       "[49930 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96654c0f-7a81-4e03-98bf-90d9d1050d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>option_order</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>seed</th>\n",
       "      <th>query</th>\n",
       "      <th>gen_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>constrained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19750 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    corpus                     model                              task  \\\n",
       "0    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "1    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "2    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "3    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "4    DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "..     ...                       ...                               ...   \n",
       "390  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "391  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "392  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "393  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "394  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "\n",
       "    eval_type option_order  Accuracy  seed         query     gen_type  \n",
       "0      direct      noOrder         1     1           NaN          NaN  \n",
       "1      direct      noOrder         1     1           NaN          NaN  \n",
       "2      direct      noOrder         1     1           NaN          NaN  \n",
       "3      direct      noOrder         0     1           NaN          NaN  \n",
       "4      direct      noOrder         1     1           NaN          NaN  \n",
       "..        ...          ...       ...   ...           ...          ...  \n",
       "390       NaN      noOrder         1     1  is plausible  constrained  \n",
       "391       NaN      noOrder         0     1  is plausible  constrained  \n",
       "392       NaN      noOrder         0     1  is plausible  constrained  \n",
       "393       NaN      noOrder         1     1  is plausible  constrained  \n",
       "394       NaN      noOrder         1     1  is plausible  constrained  \n",
       "\n",
       "[19750 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop seed = 0, No difference\n",
    "if TASKSET != \"SI\":\n",
    "    full_df = full_df.loc[full_df[\"seed\"] != 0]\n",
    "if TASKSET == \"MAIN\":\n",
    "    full_df = full_df.loc[full_df[\"gen_type\"] != \"free\"]\n",
    "    full_df = full_df.loc[full_df[\"query\"] != \"makes sense\"]\n",
    "if TASKSET == \"QUERY_COMPARISON\":\n",
    "    full_df[\"task\"] = full_df[\"task\"] + \"_\" + full_df[\"query\"]\n",
    "    full_df = full_df.loc[full_df[\"eval_type\"] != \"metaInstruct\"]\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c33455-3faa-43b3-a4db-273648af4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['eval_type'] = full_df['eval_type'].fillna(full_df['task'])\n",
    "#Get metaInstruct results\n",
    "not_nan_mask = full_df[\"eval_type\"] == \"metaInstruct\"\n",
    "full_df.loc[not_nan_mask, \"task\"] = full_df.loc[not_nan_mask, \"task\"] + \"_\" + full_df.loc[not_nan_mask, \"eval_type\"]\n",
    "if 'query' in full_df:\n",
    "    full_df['query'] = full_df['query'].fillna(\"direct\")\n",
    "if 'gen_type' in full_df:\n",
    "    full_df['gen_type'] = full_df['gen_type'].fillna(\"direct\")\n",
    "    if FREE_CONSTRAINED_SEPARATED:\n",
    "    # Split generation tasks by free/constrained\n",
    "        not_nan_mask = full_df[\"gen_type\"] != \"direct\"\n",
    "        full_df.loc[not_nan_mask, \"task\"] = full_df.loc[not_nan_mask, \"task\"] + \"_\" + full_df.loc[not_nan_mask, \"gen_type\"]\n",
    "    levels = [\"corpus\", \"model\", \"task\", \"eval_type\", \"gen_type\", \"query\", \"option_order\", \"seed\"]\n",
    "else:\n",
    "    levels = [\"corpus\", \"model\", \"task\", \"eval_type\", \"option_order\", \"seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb0c0b2-63bb-4daa-82fd-3cce4febb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>gen_type</th>\n",
       "      <th>query</th>\n",
       "      <th>option_order</th>\n",
       "      <th>seed</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.918987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>falcon-7b-instruct</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_comparison</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>badFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_comparison_metaInstruct</td>\n",
       "      <td>metaInstruct</td>\n",
       "      <td>direct</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>goodFirst</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_judge</td>\n",
       "      <td>metaQuestionComplex</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>mpt-7b-instruct</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>constrained</td>\n",
       "      <td>is plausible</td>\n",
       "      <td>noOrder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpus                     model                              task  \\\n",
       "0   DTFit  Mistral-7B-Instruct-v0.1                          logprobs   \n",
       "1   DTFit  Mistral-7B-Instruct-v0.1               sentence_comparison   \n",
       "2   DTFit  Mistral-7B-Instruct-v0.1               sentence_comparison   \n",
       "3   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison_metaInstruct   \n",
       "4   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison_metaInstruct   \n",
       "5   DTFit  Mistral-7B-Instruct-v0.1                    sentence_judge   \n",
       "6   DTFit  Mistral-7B-Instruct-v0.1  sentence_judge_generation_likert   \n",
       "7   DTFit           Mistral-7B-v0.1                          logprobs   \n",
       "8   DTFit           Mistral-7B-v0.1               sentence_comparison   \n",
       "9   DTFit           Mistral-7B-v0.1               sentence_comparison   \n",
       "10  DTFit           Mistral-7B-v0.1  sentence_comparison_metaInstruct   \n",
       "11  DTFit           Mistral-7B-v0.1  sentence_comparison_metaInstruct   \n",
       "12  DTFit           Mistral-7B-v0.1                    sentence_judge   \n",
       "13  DTFit           Mistral-7B-v0.1  sentence_judge_generation_likert   \n",
       "14  DTFit                 falcon-7b                          logprobs   \n",
       "15  DTFit                 falcon-7b               sentence_comparison   \n",
       "16  DTFit                 falcon-7b               sentence_comparison   \n",
       "17  DTFit                 falcon-7b  sentence_comparison_metaInstruct   \n",
       "18  DTFit                 falcon-7b  sentence_comparison_metaInstruct   \n",
       "19  DTFit                 falcon-7b                    sentence_judge   \n",
       "20  DTFit                 falcon-7b  sentence_judge_generation_likert   \n",
       "21  DTFit        falcon-7b-instruct                          logprobs   \n",
       "22  DTFit        falcon-7b-instruct               sentence_comparison   \n",
       "23  DTFit        falcon-7b-instruct               sentence_comparison   \n",
       "24  DTFit        falcon-7b-instruct  sentence_comparison_metaInstruct   \n",
       "25  DTFit        falcon-7b-instruct  sentence_comparison_metaInstruct   \n",
       "26  DTFit        falcon-7b-instruct                    sentence_judge   \n",
       "27  DTFit        falcon-7b-instruct  sentence_judge_generation_likert   \n",
       "28  DTFit                   gpt2-xl                          logprobs   \n",
       "29  DTFit                   gpt2-xl               sentence_comparison   \n",
       "30  DTFit                   gpt2-xl               sentence_comparison   \n",
       "31  DTFit                   gpt2-xl  sentence_comparison_metaInstruct   \n",
       "32  DTFit                   gpt2-xl  sentence_comparison_metaInstruct   \n",
       "33  DTFit                   gpt2-xl                    sentence_judge   \n",
       "34  DTFit                   gpt2-xl  sentence_judge_generation_likert   \n",
       "35  DTFit                    mpt-7b                          logprobs   \n",
       "36  DTFit                    mpt-7b               sentence_comparison   \n",
       "37  DTFit                    mpt-7b               sentence_comparison   \n",
       "38  DTFit                    mpt-7b  sentence_comparison_metaInstruct   \n",
       "39  DTFit                    mpt-7b  sentence_comparison_metaInstruct   \n",
       "40  DTFit                    mpt-7b                    sentence_judge   \n",
       "41  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
       "42  DTFit           mpt-7b-instruct                          logprobs   \n",
       "43  DTFit           mpt-7b-instruct               sentence_comparison   \n",
       "44  DTFit           mpt-7b-instruct               sentence_comparison   \n",
       "45  DTFit           mpt-7b-instruct  sentence_comparison_metaInstruct   \n",
       "46  DTFit           mpt-7b-instruct  sentence_comparison_metaInstruct   \n",
       "47  DTFit           mpt-7b-instruct                    sentence_judge   \n",
       "48  DTFit           mpt-7b-instruct  sentence_judge_generation_likert   \n",
       "\n",
       "                           eval_type     gen_type         query option_order  \\\n",
       "0                             direct       direct        direct      noOrder   \n",
       "1                metaQuestionComplex       direct  is plausible     badFirst   \n",
       "2                metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "3                       metaInstruct       direct  is plausible     badFirst   \n",
       "4                       metaInstruct       direct  is plausible    goodFirst   \n",
       "5                metaQuestionComplex       direct        direct      noOrder   \n",
       "6   sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "7                             direct       direct        direct      noOrder   \n",
       "8                metaQuestionComplex       direct  is plausible     badFirst   \n",
       "9                metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "10                      metaInstruct       direct  is plausible     badFirst   \n",
       "11                      metaInstruct       direct  is plausible    goodFirst   \n",
       "12               metaQuestionComplex       direct        direct      noOrder   \n",
       "13  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "14                            direct       direct        direct      noOrder   \n",
       "15               metaQuestionComplex       direct  is plausible     badFirst   \n",
       "16               metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "17                      metaInstruct       direct  is plausible     badFirst   \n",
       "18                      metaInstruct       direct  is plausible    goodFirst   \n",
       "19               metaQuestionComplex       direct        direct      noOrder   \n",
       "20  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "21                            direct       direct        direct      noOrder   \n",
       "22               metaQuestionComplex       direct  is plausible     badFirst   \n",
       "23               metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "24                      metaInstruct       direct  is plausible     badFirst   \n",
       "25                      metaInstruct       direct  is plausible    goodFirst   \n",
       "26               metaQuestionComplex       direct        direct      noOrder   \n",
       "27  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "28                            direct       direct        direct      noOrder   \n",
       "29               metaQuestionComplex       direct  is plausible     badFirst   \n",
       "30               metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "31                      metaInstruct       direct  is plausible     badFirst   \n",
       "32                      metaInstruct       direct  is plausible    goodFirst   \n",
       "33               metaQuestionComplex       direct        direct      noOrder   \n",
       "34  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "35                            direct       direct        direct      noOrder   \n",
       "36               metaQuestionComplex       direct  is plausible     badFirst   \n",
       "37               metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "38                      metaInstruct       direct  is plausible     badFirst   \n",
       "39                      metaInstruct       direct  is plausible    goodFirst   \n",
       "40               metaQuestionComplex       direct        direct      noOrder   \n",
       "41  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "42                            direct       direct        direct      noOrder   \n",
       "43               metaQuestionComplex       direct  is plausible     badFirst   \n",
       "44               metaQuestionComplex       direct  is plausible    goodFirst   \n",
       "45                      metaInstruct       direct  is plausible     badFirst   \n",
       "46                      metaInstruct       direct  is plausible    goodFirst   \n",
       "47               metaQuestionComplex       direct        direct      noOrder   \n",
       "48  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
       "\n",
       "    seed  Accuracy  \n",
       "0      1  0.934177  \n",
       "1      1  0.908861  \n",
       "2      1  0.954430  \n",
       "3      1  0.000000  \n",
       "4      1  1.000000  \n",
       "5      1  0.594937  \n",
       "6      1  0.726582  \n",
       "7      1  0.906329  \n",
       "8      1  0.949367  \n",
       "9      1  0.845570  \n",
       "10     1  0.000000  \n",
       "11     1  1.000000  \n",
       "12     1  0.230380  \n",
       "13     1  0.506329  \n",
       "14     1  0.918987  \n",
       "15     1  0.000000  \n",
       "16     1  1.000000  \n",
       "17     1  0.762025  \n",
       "18     1  0.202532  \n",
       "19     1  0.245570  \n",
       "20     1  0.374684  \n",
       "21     1  0.913924  \n",
       "22     1  0.002532  \n",
       "23     1  0.997468  \n",
       "24     1  0.053165  \n",
       "25     1  0.913924  \n",
       "26     1  0.131646  \n",
       "27     1  0.455696  \n",
       "28     1  0.875949  \n",
       "29     1  0.000000  \n",
       "30     1  1.000000  \n",
       "31     1  0.946835  \n",
       "32     1  0.103797  \n",
       "33     1  0.000000  \n",
       "34     1  0.437975  \n",
       "35     1  0.934177  \n",
       "36     1  0.000000  \n",
       "37     1  1.000000  \n",
       "38     1  0.000000  \n",
       "39     1  1.000000  \n",
       "40     1  0.111392  \n",
       "41     1  0.425316  \n",
       "42     1  0.926582  \n",
       "43     1  0.075949  \n",
       "44     1  0.855696  \n",
       "45     1  0.000000  \n",
       "46     1  1.000000  \n",
       "47     1  0.336709  \n",
       "48     1  0.384810  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "grouped = full_df.groupby(levels)[\"Accuracy\"].mean().reset_index()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4bc7fad-8fd0-4a18-b90b-22bd892f4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude levels \"option_order\", \"seed\"\n",
    "levels = [elm for elm in levels if elm not in [\"option_order\", \"seed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d12caa33-684d-4f45-b4d7-c5035b9fae2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGPROBS\n",
      "   corpus                     model      task eval_type gen_type   query  \\\n",
      "0   DTFit  Mistral-7B-Instruct-v0.1  logprobs    direct   direct  direct   \n",
      "7   DTFit           Mistral-7B-v0.1  logprobs    direct   direct  direct   \n",
      "14  DTFit                 falcon-7b  logprobs    direct   direct  direct   \n",
      "21  DTFit        falcon-7b-instruct  logprobs    direct   direct  direct   \n",
      "28  DTFit                   gpt2-xl  logprobs    direct   direct  direct   \n",
      "35  DTFit                    mpt-7b  logprobs    direct   direct  direct   \n",
      "42  DTFit           mpt-7b-instruct  logprobs    direct   direct  direct   \n",
      "\n",
      "   option_order  seed  Accuracy  \n",
      "0       noOrder     1  0.934177  \n",
      "7       noOrder     1  0.906329  \n",
      "14      noOrder     1  0.918987  \n",
      "21      noOrder     1  0.913924  \n",
      "28      noOrder     1  0.875949  \n",
      "35      noOrder     1  0.934177  \n",
      "42      noOrder     1  0.926582  \n",
      "Length: 7\n",
      "*****\n",
      "SENTENCE_COMPARISON\n",
      "   corpus                     model                 task            eval_type  \\\n",
      "1   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison  metaQuestionComplex   \n",
      "2   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison  metaQuestionComplex   \n",
      "8   DTFit           Mistral-7B-v0.1  sentence_comparison  metaQuestionComplex   \n",
      "9   DTFit           Mistral-7B-v0.1  sentence_comparison  metaQuestionComplex   \n",
      "15  DTFit                 falcon-7b  sentence_comparison  metaQuestionComplex   \n",
      "16  DTFit                 falcon-7b  sentence_comparison  metaQuestionComplex   \n",
      "22  DTFit        falcon-7b-instruct  sentence_comparison  metaQuestionComplex   \n",
      "23  DTFit        falcon-7b-instruct  sentence_comparison  metaQuestionComplex   \n",
      "29  DTFit                   gpt2-xl  sentence_comparison  metaQuestionComplex   \n",
      "30  DTFit                   gpt2-xl  sentence_comparison  metaQuestionComplex   \n",
      "36  DTFit                    mpt-7b  sentence_comparison  metaQuestionComplex   \n",
      "37  DTFit                    mpt-7b  sentence_comparison  metaQuestionComplex   \n",
      "43  DTFit           mpt-7b-instruct  sentence_comparison  metaQuestionComplex   \n",
      "44  DTFit           mpt-7b-instruct  sentence_comparison  metaQuestionComplex   \n",
      "\n",
      "   gen_type         query option_order  seed  Accuracy  \n",
      "1    direct  is plausible     badFirst     1  0.908861  \n",
      "2    direct  is plausible    goodFirst     1  0.954430  \n",
      "8    direct  is plausible     badFirst     1  0.949367  \n",
      "9    direct  is plausible    goodFirst     1  0.845570  \n",
      "15   direct  is plausible     badFirst     1  0.000000  \n",
      "16   direct  is plausible    goodFirst     1  1.000000  \n",
      "22   direct  is plausible     badFirst     1  0.002532  \n",
      "23   direct  is plausible    goodFirst     1  0.997468  \n",
      "29   direct  is plausible     badFirst     1  0.000000  \n",
      "30   direct  is plausible    goodFirst     1  1.000000  \n",
      "36   direct  is plausible     badFirst     1  0.000000  \n",
      "37   direct  is plausible    goodFirst     1  1.000000  \n",
      "43   direct  is plausible     badFirst     1  0.075949  \n",
      "44   direct  is plausible    goodFirst     1  0.855696  \n",
      "Length: 14\n",
      "*****\n",
      "SENTENCE_COMPARISON_METAINSTRUCT\n",
      "   corpus                     model                              task  \\\n",
      "3   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison_metaInstruct   \n",
      "4   DTFit  Mistral-7B-Instruct-v0.1  sentence_comparison_metaInstruct   \n",
      "10  DTFit           Mistral-7B-v0.1  sentence_comparison_metaInstruct   \n",
      "11  DTFit           Mistral-7B-v0.1  sentence_comparison_metaInstruct   \n",
      "17  DTFit                 falcon-7b  sentence_comparison_metaInstruct   \n",
      "18  DTFit                 falcon-7b  sentence_comparison_metaInstruct   \n",
      "24  DTFit        falcon-7b-instruct  sentence_comparison_metaInstruct   \n",
      "25  DTFit        falcon-7b-instruct  sentence_comparison_metaInstruct   \n",
      "31  DTFit                   gpt2-xl  sentence_comparison_metaInstruct   \n",
      "32  DTFit                   gpt2-xl  sentence_comparison_metaInstruct   \n",
      "38  DTFit                    mpt-7b  sentence_comparison_metaInstruct   \n",
      "39  DTFit                    mpt-7b  sentence_comparison_metaInstruct   \n",
      "45  DTFit           mpt-7b-instruct  sentence_comparison_metaInstruct   \n",
      "46  DTFit           mpt-7b-instruct  sentence_comparison_metaInstruct   \n",
      "\n",
      "       eval_type gen_type         query option_order  seed  Accuracy  \n",
      "3   metaInstruct   direct  is plausible     badFirst     1  0.000000  \n",
      "4   metaInstruct   direct  is plausible    goodFirst     1  1.000000  \n",
      "10  metaInstruct   direct  is plausible     badFirst     1  0.000000  \n",
      "11  metaInstruct   direct  is plausible    goodFirst     1  1.000000  \n",
      "17  metaInstruct   direct  is plausible     badFirst     1  0.762025  \n",
      "18  metaInstruct   direct  is plausible    goodFirst     1  0.202532  \n",
      "24  metaInstruct   direct  is plausible     badFirst     1  0.053165  \n",
      "25  metaInstruct   direct  is plausible    goodFirst     1  0.913924  \n",
      "31  metaInstruct   direct  is plausible     badFirst     1  0.946835  \n",
      "32  metaInstruct   direct  is plausible    goodFirst     1  0.103797  \n",
      "38  metaInstruct   direct  is plausible     badFirst     1  0.000000  \n",
      "39  metaInstruct   direct  is plausible    goodFirst     1  1.000000  \n",
      "45  metaInstruct   direct  is plausible     badFirst     1  0.000000  \n",
      "46  metaInstruct   direct  is plausible    goodFirst     1  1.000000  \n",
      "Length: 14\n",
      "*****\n",
      "SENTENCE_JUDGE\n",
      "   corpus                     model            task            eval_type  \\\n",
      "5   DTFit  Mistral-7B-Instruct-v0.1  sentence_judge  metaQuestionComplex   \n",
      "12  DTFit           Mistral-7B-v0.1  sentence_judge  metaQuestionComplex   \n",
      "19  DTFit                 falcon-7b  sentence_judge  metaQuestionComplex   \n",
      "26  DTFit        falcon-7b-instruct  sentence_judge  metaQuestionComplex   \n",
      "33  DTFit                   gpt2-xl  sentence_judge  metaQuestionComplex   \n",
      "40  DTFit                    mpt-7b  sentence_judge  metaQuestionComplex   \n",
      "47  DTFit           mpt-7b-instruct  sentence_judge  metaQuestionComplex   \n",
      "\n",
      "   gen_type   query option_order  seed  Accuracy  \n",
      "5    direct  direct      noOrder     1  0.594937  \n",
      "12   direct  direct      noOrder     1  0.230380  \n",
      "19   direct  direct      noOrder     1  0.245570  \n",
      "26   direct  direct      noOrder     1  0.131646  \n",
      "33   direct  direct      noOrder     1  0.000000  \n",
      "40   direct  direct      noOrder     1  0.111392  \n",
      "47   direct  direct      noOrder     1  0.336709  \n",
      "Length: 7\n",
      "*****\n",
      "SENTENCE_JUDGE_GENERATION_LIKERT\n",
      "   corpus                     model                              task  \\\n",
      "6   DTFit  Mistral-7B-Instruct-v0.1  sentence_judge_generation_likert   \n",
      "13  DTFit           Mistral-7B-v0.1  sentence_judge_generation_likert   \n",
      "20  DTFit                 falcon-7b  sentence_judge_generation_likert   \n",
      "27  DTFit        falcon-7b-instruct  sentence_judge_generation_likert   \n",
      "34  DTFit                   gpt2-xl  sentence_judge_generation_likert   \n",
      "41  DTFit                    mpt-7b  sentence_judge_generation_likert   \n",
      "48  DTFit           mpt-7b-instruct  sentence_judge_generation_likert   \n",
      "\n",
      "                           eval_type     gen_type         query option_order  \\\n",
      "6   sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "13  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "20  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "27  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "34  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "41  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "48  sentence_judge_generation_likert  constrained  is plausible      noOrder   \n",
      "\n",
      "    seed  Accuracy  \n",
      "6      1  0.726582  \n",
      "13     1  0.506329  \n",
      "20     1  0.374684  \n",
      "27     1  0.455696  \n",
      "34     1  0.437975  \n",
      "41     1  0.425316  \n",
      "48     1  0.384810  \n",
      "Length: 7\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "for t in grouped.task.unique():\n",
    "    print(t.upper())\n",
    "    sub_df = grouped.loc[grouped[\"task\"] == t]\n",
    "    print(sub_df)\n",
    "    print(f\"Length: {len(sub_df)}\")\n",
    "    print(\"*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2ebdf-f1b4-4de0-8abd-a3ff7b163aa9",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45658c29-fdbd-4aba-ac80-5b1a40572228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['logprobs', 'sentence_comparison_metaInstruct',\n",
       "       'sentence_comparison', 'sentence_judge',\n",
       "       'sentence_judge_generation_likert'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15031cae-f38a-4696-b836-cc9e091b113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3909470/1322586004.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  plot_df['model'] = pd.Categorical(plot_df['model'], categories=MODEL_LIST, ordered=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>logprobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>mpt-7b</td>\n",
       "      <td>sentence_judge_generation_likert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model                              task  Accuracy\n",
       "0    Mistral-7B-Instruct-v0.1                          logprobs         1\n",
       "1    Mistral-7B-Instruct-v0.1                          logprobs         1\n",
       "2    Mistral-7B-Instruct-v0.1                          logprobs         1\n",
       "3    Mistral-7B-Instruct-v0.1                          logprobs         0\n",
       "4    Mistral-7B-Instruct-v0.1                          logprobs         1\n",
       "..                        ...                               ...       ...\n",
       "390                    mpt-7b  sentence_judge_generation_likert         1\n",
       "391                    mpt-7b  sentence_judge_generation_likert         0\n",
       "392                    mpt-7b  sentence_judge_generation_likert         0\n",
       "393                    mpt-7b  sentence_judge_generation_likert         1\n",
       "394                    mpt-7b  sentence_judge_generation_likert         1\n",
       "\n",
       "[19750 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NEW\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plot_df = full_df[[\"model\", \"task\", \"Accuracy\"]]\n",
    "\n",
    "plot_df['model'] = pd.Categorical(plot_df['model'], categories=MODEL_LIST, ordered=True)\n",
    "if TASKSET == \"MAIN\":\n",
    "    to = [elm for elm in task_order if elm in list(plot_df.task)]\n",
    "    # Subset for tasks\n",
    "    plot_df = plot_df.loc[plot_df.task.isin(task_order)]\n",
    "    plot_df['task'] = pd.Categorical(plot_df['task'], categories=to, ordered=True)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3100fea-b6fd-4e91-b20d-c6ec08ff58ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logprobs', 'sentence_comparison_metaInstruct', 'sentence_comparison', 'sentence_judge', 'sentence_judge_generation_likert']\n",
       "Categories (5, object): ['logprobs' < 'sentence_comparison' < 'sentence_comparison_metaInstruct' < 'sentence_judge_generation_likert' < 'sentence_judge']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fb8c017-400e-4c5c-88ae-c0c59b932adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_csv(f\"{DATASET}.{TASKSET}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ab3bd75-5941-4abc-a9d6-bd378c1bbbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>Mean_Accuracy</th>\n",
       "      <th>SEM_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTFit</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>0.005044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus  Mean_Accuracy  SEM_Accuracy\n",
       "0  DTFit       0.989873      0.005044"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add human data\n",
    "human_data_path = os.path.abspath(f'../datasets/single_sentences/DTFit/corpus.csv')\n",
    "human_df = pd.read_csv(human_data_path)\n",
    "human_df[\"corpus\"] = \"DTFit\"\n",
    "human_df[\"Accuracy\"] = human_df.apply(\n",
    "            lambda row: 1 if row.good_human_score > row.bad_human_score else 0, axis=1)\n",
    "\n",
    "human_df.to_csv(f\"{DATASET}.{TASKSET}.human.csv\")\n",
    "\n",
    "# get vals\n",
    "human_values = human_df.groupby(\"corpus\")[\"Accuracy\"].agg(['mean', 'sem']).reset_index()\n",
    "human_values.columns = ['corpus', 'Mean_Accuracy', 'SEM_Accuracy']\n",
    "human_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad83892f-4205-49e1-854f-7df907921f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2625365/3662036524.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(labels = new_labels, rotation=0, fontweight='normal')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "\n",
    "ax = sns.barplot(data=plot_df, x=\"task\", y=\"Accuracy\", hue=\"model\", edgecolor='black', linewidth=1, errorbar=\"se\",\n",
    "                 palette=MODEL_PAL, capsize=0.2, err_kws={'linewidth': 1.5})\n",
    "\n",
    "# Extract text from each Text object\n",
    "xticklabels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "new_labels = []\n",
    "for task in xticklabels:\n",
    "    if (TASKSET == \"GENERATION\") & (\"generation\" in task):\n",
    "        new_labels.append(f\"{BETTER_TASK_NAMES['_'.join(task.split('_')[:-1])]}\\n[{task.split('_')[-1]}]\")\n",
    "    elif TASKSET == \"QUERY_COMPARISON\":\n",
    "        new_labels.append(f\"{BETTER_TASK_NAMES['_'.join(task.split('_')[:-1])]}\\n['{task.split('_')[-1]}']\")\n",
    "    else:\n",
    "        new_labels.append(BETTER_TASK_NAMES[task])\n",
    "\n",
    "ax.set_xticklabels(labels = new_labels, rotation=0, fontweight='normal')\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "# add chance level lines\n",
    "x_range = ax.get_xlim()\n",
    "if \"sentence_judge\" in xticklabels:\n",
    "    # Plot a dotted line at height 0.5\n",
    "    ax.plot([x_range[0] , x_range[1] - 1], [0.5, 0.5], linestyle=\":\", color=\"gray\", alpha=1, linewidth=2, label=\"Chance\")\n",
    "    # Plot a dotted line at height 0.25\n",
    "    ax.plot([x_range[1] - 1 , x_range[1]], [0.25, 0.25], linestyle=\":\", color=\"gray\", alpha=1, linewidth=2)\n",
    "else:\n",
    "    ax.axhline(y=0.5, linestyle=\":\", color=\"gray\", alpha=1, linewidth=2, label=\"Chance\")\n",
    "\n",
    "# Fix ylim\n",
    "plt.ylim(0,1)\n",
    "\n",
    "human_baseline = human_values.loc[human_values.corpus == \"DTFit\"].Mean_Accuracy.item()\n",
    "human_error = human_values.loc[human_values.corpus == \"DTFit\"].SEM_Accuracy.item()\n",
    "\n",
    "# Calculate the y-range for the shaded area\n",
    "ymin = human_baseline - human_error\n",
    "ymax = human_baseline + human_error\n",
    "# Add shaded error around the horizontal line\n",
    "ax.fill_betweenx(y=[ymin, ymax], x1=x_range[0], x2=x_range[1], color=MODEL_PAL[\"human\"], alpha=0.2)\n",
    "ax.axhline(y=human_baseline, linestyle=\"-\", color=MODEL_PAL[\"human\"], alpha=1, linewidth=2) #, label=\"human\") #MODEL_PAL[\"human\"]\n",
    "# Add line annotation\n",
    "ax.text(x_range[1], ymin - 0.01, \"Human performance\", verticalalignment='top', horizontalalignment='right') #,\n",
    "        #bbox=dict(facecolor=MODEL_PAL[\"human\"], alpha=0.2, boxstyle='round,pad=0.2'))\n",
    "\n",
    "\n",
    "# Add title\n",
    "# Load the icon image\n",
    "aa_icon_path = 'animate-animate.png'\n",
    "ai_icon_path = 'animate-inanimate-laptop.png'\n",
    "\n",
    "if TASKSET == \"MAIN\":\n",
    "    title = \"DTFit [AI, unlikely]\"\n",
    "elif TASKSET == \"GENERATION\":\n",
    "    title = \"Generation Prompting (DTFit [AI, unlikely])\"\n",
    "elif TASKSET == \"QUERY_COMPARISON\":\n",
    "    title = \"Query Comparison (DTFit [AI, unlikely])\"   \n",
    "\n",
    "ax.set_title(title, fontweight='bold', fontsize=\"large\", pad=15)\n",
    "icon = mpimg.imread(ai_icon_path)\n",
    "\n",
    "# Create an offset image\n",
    "imagebox = OffsetImage(icon, zoom=0.03)\n",
    "imagebox.image.axes = ax\n",
    "\n",
    "# Create an AnnotationBbox\n",
    "ab = AnnotationBbox(imagebox, (0.91, 1.05), xycoords='axes fraction', frameon=False)\n",
    "\n",
    "# Add the icon to the subplot\n",
    "ax.add_artist(ab)\n",
    "\n",
    "# Style and add legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [PRETTYNAMES[elm] if elm in PRETTYNAMES else elm for elm in labels]\n",
    "\n",
    "if TASKSET == \"MAIN\":\n",
    "    legend_loc = -0.28\n",
    "elif TASKSET == \"QUERY_COMPARISON\":\n",
    "    legend_loc = -0.28\n",
    "else:\n",
    "    legend_loc = -0.32\n",
    "    # Put a legend to the right of the current axis\n",
    "ax.legend(handles, new_labels, loc='lower center', bbox_to_anchor=(0.5, legend_loc),\n",
    "          ncol=4, frameon=True, fontsize='medium')\n",
    "\n",
    "plt.margins(x=0.001)\n",
    "    \n",
    "# Adjust the layout and display the plot\n",
    "plt.subplots_adjust(top=0.9)  # Adjust the top of the subplots for the suptitle\n",
    "\n",
    "plt.savefig(f'figures/PromptChoice.{DATASET}.{TASKSET}.svg', dpi=280, bbox_inches=\"tight\")\n",
    "plt.savefig(f'figures/PromptChoice.{DATASET}.{TASKSET}.png', dpi=280, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd57328d-6da0-4648-9a82-46c36a1c4a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGPROBS\n",
      "                      model  NumCorrect  NumTotal  AccuracyScore  \\\n",
      "0           Mistral-7B-v0.1         358       395       0.906329   \n",
      "1  Mistral-7B-Instruct-v0.1         369       395       0.934177   \n",
      "2                 falcon-7b         363       395       0.918987   \n",
      "3        falcon-7b-instruct         361       395       0.913924   \n",
      "4                    mpt-7b         369       395       0.934177   \n",
      "5           mpt-7b-instruct         366       395       0.926582   \n",
      "6                   gpt2-xl         346       395       0.875949   \n",
      "\n",
      "           pVal  pValAdjusted significance  \n",
      "0  4.175373e-67  4.871269e-67          ***  \n",
      "1  9.254456e-79  3.239059e-78          ***  \n",
      "2  3.503476e-72  6.131083e-72          ***  \n",
      "3  4.130286e-70  5.782400e-70          ***  \n",
      "4  9.254456e-79  3.239059e-78          ***  \n",
      "5  2.123542e-75  4.954931e-75          ***  \n",
      "6  3.628780e-56  3.628780e-56          ***  \n",
      "\n",
      "\n",
      "\n",
      "SENTENCE_COMPARISON\n",
      "                      model  NumCorrect  NumTotal  AccuracyScore  \\\n",
      "0           Mistral-7B-v0.1         709       790       0.897468   \n",
      "1  Mistral-7B-Instruct-v0.1         736       790       0.931646   \n",
      "2                 falcon-7b         395       790       0.500000   \n",
      "3        falcon-7b-instruct         395       790       0.500000   \n",
      "4                    mpt-7b         395       790       0.500000   \n",
      "5           mpt-7b-instruct         368       790       0.465823   \n",
      "6                   gpt2-xl         395       790       0.500000   \n",
      "\n",
      "            pVal   pValAdjusted significance  \n",
      "0  4.359969e-126  1.525989e-125          ***  \n",
      "1  6.665128e-154  4.665590e-153          ***  \n",
      "2   1.000000e+00   1.000000e+00         n.s.  \n",
      "3   1.000000e+00   1.000000e+00         n.s.  \n",
      "4   1.000000e+00   1.000000e+00         n.s.  \n",
      "5   5.927282e-02   1.383032e-01         n.s.  \n",
      "6   1.000000e+00   1.000000e+00         n.s.  \n",
      "\n",
      "\n",
      "\n",
      "SENTENCE_COMPARISON_METAINSTRUCT\n",
      "                      model  NumCorrect  NumTotal  AccuracyScore      pVal  \\\n",
      "0           Mistral-7B-v0.1         395       790       0.500000  1.000000   \n",
      "1  Mistral-7B-Instruct-v0.1         395       790       0.500000  1.000000   \n",
      "2                 falcon-7b         381       790       0.482278  0.336749   \n",
      "3        falcon-7b-instruct         382       790       0.483544  0.373766   \n",
      "4                    mpt-7b         395       790       0.500000  1.000000   \n",
      "5           mpt-7b-instruct         395       790       0.500000  1.000000   \n",
      "6                   gpt2-xl         415       790       0.525316  0.165231   \n",
      "\n",
      "   pValAdjusted significance  \n",
      "0      1.000000         n.s.  \n",
      "1      1.000000         n.s.  \n",
      "2      0.872122         n.s.  \n",
      "3      0.872122         n.s.  \n",
      "4      1.000000         n.s.  \n",
      "5      1.000000         n.s.  \n",
      "6      0.872122         n.s.  \n",
      "\n",
      "\n",
      "\n",
      "SENTENCE_JUDGE_GENERATION_LIKERT\n",
      "                      model  NumCorrect  NumTotal  AccuracyScore  \\\n",
      "0           Mistral-7B-v0.1         200       395       0.506329   \n",
      "1  Mistral-7B-Instruct-v0.1         287       395       0.726582   \n",
      "2                 falcon-7b         148       395       0.374684   \n",
      "3        falcon-7b-instruct         180       395       0.455696   \n",
      "4                    mpt-7b         168       395       0.425316   \n",
      "5           mpt-7b-instruct         152       395       0.384810   \n",
      "6                   gpt2-xl         173       395       0.437975   \n",
      "\n",
      "           pVal  pValAdjusted significance  \n",
      "0  8.405258e-01  8.405258e-01         n.s.  \n",
      "1  7.647948e-20  5.353563e-19          ***  \n",
      "2  7.206110e-07  2.522139e-06          ***  \n",
      "3  8.700326e-02  1.015038e-01         n.s.  \n",
      "4  3.467211e-03  6.067619e-03           **  \n",
      "5  5.431634e-06  1.267381e-05          ***  \n",
      "6  1.562252e-02  2.187153e-02            *  \n",
      "\n",
      "\n",
      "\n",
      "SENTENCE_JUDGE\n",
      "                      model  NumCorrect  NumTotal  AccuracyScore  \\\n",
      "0           Mistral-7B-v0.1         182       790       0.230380   \n",
      "1  Mistral-7B-Instruct-v0.1         235       395       0.594937   \n",
      "2                 falcon-7b          97       395       0.245570   \n",
      "3        falcon-7b-instruct          52       395       0.131646   \n",
      "4                    mpt-7b          44       395       0.111392   \n",
      "5           mpt-7b-instruct         133       395       0.336709   \n",
      "6                   gpt2-xl           0       395       0.000000   \n",
      "\n",
      "           pVal  pValAdjusted significance  \n",
      "0  2.176902e-01  2.539719e-01         n.s.  \n",
      "1  1.697135e-47  5.939971e-47          ***  \n",
      "2  8.618495e-01  8.618495e-01         n.s.  \n",
      "3  9.356355e-09  1.637362e-08          ***  \n",
      "4  6.305660e-12  1.471321e-11          ***  \n",
      "5  1.190085e-04  1.666118e-04          ***  \n",
      "6  7.134067e-50  4.993847e-49          ***  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binomtest, chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def assign_significance_labels(pvals):\n",
    "    return [\"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"n.s.\" for p in pvals]\n",
    "\n",
    "def calculate_binom_pval(num_correct, num_total, task):\n",
    "    if task == \"sentence_judge\":\n",
    "        p=0.25\n",
    "    else:\n",
    "        p=0.5\n",
    "    return binomtest(k=num_correct, n=num_total, p=p).pvalue\n",
    "\n",
    "for task in task_order:\n",
    "    print(task.upper())\n",
    "    sub_df = plot_df.loc[plot_df[\"task\"] == task]\n",
    "        # Calculate p-values for binomial test\n",
    "    dat_binchoice_summary = sub_df.groupby('model').agg(NumCorrect=('Accuracy', 'sum'), NumTotal=('Accuracy', 'count')) \\\n",
    "        .reset_index() \\\n",
    "        .assign(AccuracyScore=lambda x: x['NumCorrect'] / x['NumTotal'])\n",
    "\n",
    "    dat_binchoice_summary['pVal'] = dat_binchoice_summary.apply(lambda row: calculate_binom_pval(row['NumCorrect'], row['NumTotal'], task), axis=1)\n",
    "    dat_binchoice_summary['pValAdjusted'] = multipletests(dat_binchoice_summary['pVal'], method='fdr_bh')[1]\n",
    "    dat_binchoice_summary['significance'] = assign_significance_labels(dat_binchoice_summary['pValAdjusted'])\n",
    "    print(dat_binchoice_summary)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f81b3-20a0-47d4-8235-a6a1f15af548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
